{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3da131-e0a1-4c83-a3ba-4f81762384b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import langchain dir loader from document loaders\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "directory = './contents'\n",
    "\n",
    "def load_docs(directory):\n",
    "    loader = DirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "documents = load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b286fc98-0f8d-41c6-aa02-1675c2230e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use text splitter to split text in chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# split the docs into chunks using recursive character splitter\n",
    "def split_docs(documents,chunk_size=100,chunk_overlap=2):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "# store the splitte documnets in docs variable\n",
    "docs = split_docs(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60fd781f-459b-43b9-b6e1-f7f6b7bca9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings using langchain\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Assuming docs is a list of your documents and embeddings is a list of their corresponding embeddings\n",
    "text_embeddings = zip(docs, embeddings)\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "# db = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538457cf-cbdc-417d-992f-ec145ead10ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Doing similarity search  using query\n",
    "# # query = \"How much Interim dividend was given by ITC?\"\n",
    "\n",
    "# embedding_vector = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\").embed_query(\"How much Interim dividend was given by ITC?\")\n",
    "# matching_docs = db.similarity_search_by_vector(embedding_vector)\n",
    "\n",
    "# matching_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ff5a4f7-c06d-42d0-b62d-7f25f35ba81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert an openai key below parameter\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xxxxxxxxx\"\n",
    "\n",
    "# load the LLM model\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name=model_name)\n",
    "\n",
    "# Using q&a chain to get the answer for our query\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\",verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6427c39-94d4-44b4-b069-ad69eb754979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The interim dividend given by ITC was Rs. 103,520.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your query and perform similarity search to generate an answer\n",
    "query = \"How much Interim dividend was given by ITC?\"\n",
    "\n",
    "embedding_vector = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\").embed_query(query)\n",
    "matching_docs = db.similarity_search_by_vector(embedding_vector)\n",
    "\n",
    "answer =  chain.run(input_documents=matching_docs, question=query,)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c35f3-880b-4a2a-95d6-e3388ad8460a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
